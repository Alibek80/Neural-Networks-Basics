{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выбор: либо обучить сверточную нейронную сеть на любом датасете, который не использовался на уроке, либо реализовать нейронную сеть AlexNet на любом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка параметров нейросети\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_alexnet_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n"
     ]
    }
   ],
   "source": [
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ntmpFeatures = []\\nfor feature in x_train:\\n    tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\\n    tmpFeatures.append(tmpFeature)\\n\\nx_train_resized = np.asarray(tmpFeatures)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "tmpFeatures = []\n",
    "for feature in x_train:\n",
    "    tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "    tmpFeatures.append(tmpFeature)\n",
    "\n",
    "x_train_resized = np.asarray(tmpFeatures)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_resized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AlexNet_Summary_Table.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как данные в датасете значительно меньше (32-32-3), чем входящая размерность Алекснет (227-227-3), то понизим показатели нашей копии, чтобы она могла работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "# 1st convolutional layer\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), strides=(4,4), padding='valid', input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "# 2nd convolutional layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "# 3rd convolutional layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "# 4th convolutional layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "# 5th convolutional layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#1st full connected layer\n",
    "# model.add(Dense(9216))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "#2nd full connected layer\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#3rd full connected layer\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 96)          2688      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 21,589,898\n",
      "Trainable params: 21,589,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 2.1539 - accuracy: 0.1551 - val_loss: 1.8549 - val_accuracy: 0.2675\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 1.7293 - accuracy: 0.3274 - val_loss: 1.5967 - val_accuracy: 0.3891\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 1.5627 - accuracy: 0.4183 - val_loss: 1.4215 - val_accuracy: 0.4736\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 1.4555 - accuracy: 0.4743 - val_loss: 1.3373 - val_accuracy: 0.5130\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 1.3970 - accuracy: 0.4950 - val_loss: 1.3679 - val_accuracy: 0.5120\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 1.3568 - accuracy: 0.5167 - val_loss: 1.2693 - val_accuracy: 0.5460\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 1.3226 - accuracy: 0.5311 - val_loss: 1.3011 - val_accuracy: 0.5465\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 1.2942 - accuracy: 0.5398 - val_loss: 1.2343 - val_accuracy: 0.5634\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 1.2765 - accuracy: 0.5494 - val_loss: 1.2167 - val_accuracy: 0.5659\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 1.2563 - accuracy: 0.5551 - val_loss: 1.2271 - val_accuracy: 0.5615\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сохранить обученную модель как C:\\Users\\alibe\\OneDrive\\Geekbrains\\Введение в нейронные сети\\Homework\\saved_models\\keras_cifar10_alexnet_model.h5 \n"
     ]
    }
   ],
   "source": [
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 230us/step\n",
      "Test loss: 1.2271061796188354\n",
      "Test accuracy: 0.5615000128746033\n"
     ]
    }
   ],
   "source": [
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность модели составила 56%, чтобы применить Алекснет пришлось адаптировать модель к маленьким данным - удалить один полносвязный слой, уменьшить размеры ядер у конволюционных слоев, увеличить размер батча, добавить дропауты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
